# how do i aggregate all this data from this disparate spreadsheets?
# closest I can think of is my loop below which retrieves for a filename
# Subject 80 "bad"?
#install.packages("xlsx")
library(xlsx)
dataSheets = c("Debrief", "Distraction_Assignment", "Note_sheet",
"Post-Questionnaire", "Writing_Task_Evaluation")
outList = vector("list", length=length(dataSheets))
names(outList) = dataSheets
dat = data.frame(NULL)
for (i in 1:length(dataSheets)) {
path = "./raw_data/"
RAs = substr(list.files(path = path, pattern=dataSheets[i]), nchar(dataSheets[i])+2, nchar(dataSheets[i])+3)
for (j in 1:length(RAs)) {
fileName = paste(path, dataSheets[i], "_", RAs[j], ".xlsx", sep="")
temp = read.xlsx(fileName, 1, stringsAsFactors=F)
temp$Entrant = RAs[j]
print(fileName); print(names(temp))
dat = rbind(dat, temp)
# Save to an object with variable name
# I'm going to use eval(parse()) and you don't get to pretend you're better than me
}
outList[[i]] = dat
dat = data.frame(NULL)
}
# fix subno name
names(outList[[2]])[1] = "Subject"
# checking for duplicates (e.g. two different subs entered w/ same ID)
# Note that it is right that "digits" has frequent duplicates!
for (i in 1:length(dataSheets)) {
print(names(outList)[i])
print(subset(table(outList[[i]]$Subject), table(outList[[i]]$Subject)>1))
}
debrief = outList[[1]]
debrief[debrief$Subject == 168,] # bad
debrief = debrief[!(debrief$Subject %in% c("165 or 166?", "168")),]
# Gonna put thse back into list b/c I think that makes reshaping easier
outList[[1]] = debrief ###
distract = outList[[2]]
distract = distract[!(distract$Subject %in% c(168, 170, 203, 33)),] # ??? doesn't remove rows?
distract = distract[!(distract$Subject == "165 or 167?"),]
distract = distract[complete.cases(distract),]
#
outList[[2]] = distract ###
notes = outList[[3]]
notes[notes$Subject == 150,]
notes = notes[-265,] # deleting duplicate row
#
outList[[3]] = notes ###
postQ = outList[[4]]
eval = outList[[5]]
eval = eval[!(eval$Subject %in% c(140, 63, 82)),]
#
outList[[5]] = eval ###
# Bring in digits data, previously cleaned in 2d4d.R
digits = read.delim("./cleaned_data/2d4d.txt")
names(digits)[1] = "Subject"
outList[[6]] = digits
# Aggregate everything into a single huge spreadsheet
require(reshape2)
molten = melt(outList, id.var = "Subject")
outDat = dcast(molten, Subject ~ ...)
# If it's aggregating, you've done it wrong!
outDat$Violence = ifelse(outDat$Condition_Note_sheet == 1 |
outDat$Condition_Note_sheet == 2, "Violent", "Nonviolent")
outDat$Difficulty = ifelse(outDat$Condition_Note_sheet == 2 |
outDat$Condition_Note_sheet == 4, "Hard", "Easy")
table(outDat$Condition_Note_sheet, outDat$Violence, outDat$Difficulty, useNA='always')
# may tidy up column order here, make more columns, prettier names, etc.
write.table("./cleaned_data/aggregated_data.txt", sep="\t", row.names=F)
# Gunk below from previous analysis script.
write.table(outDat, "./cleaned_data/aggregated_data.txt", sep="\t", row.names=F)
?lm.boot
d1 = data.frame("ID"=1:4)
d2 = data.frame("ID"=4:1, "Condition" = "D", "C", "B", "A")
d3 = data.frame("ID"=c(1,2,2,4), "Outcome" = c(0, 0, 1, 1))
dat = cbind(d1, d2[match(d1$ID, d2$ID),], d3[match(d1$ID, d3$ID),])
dat
?match
d1 = data.frame("ID"=1:4)
d2 = data.frame("ID"=4:1, "Condition" = c("D", "C", "B", "A"))
d3 = data.frame("ID"=c(1,2,2,4), "Outcome" = c(0, 0, 1, 1))
dat = cbind(d1, d2[match(d1$ID, d2$ID),], d3[match(d1$ID, d3$ID),])
dat
dat = cbind(d1, d2[match(d1$ID, d2$ID), -1], d3[match(d1$ID, d3$ID), -1])
dat
dat = cbind(d1, d2[match(d1$ID, d2$ID),], d3[match(d1$ID, d3$ID),])
dat
library(xlsx)
dataSheets = c("Debrief", "Distraction_Assignment", "Note_sheet",
"Post-Questionnaire", "Writing_Task_Evaluation")
outList = vector("list", length=length(dataSheets))
names(outList) = dataSheets
dat = data.frame(NULL)
i=Post-Questionnaire
i="Post-Questionnaire"
path = "./raw_data/"
RAs = substr(list.files(path = path, pattern=dataSheets[i]), nchar(dataSheets[i])+2, nchar(dataSheets[i])+3)
dataSheets = c("Debrief", "Distraction_Assignment", "Note_sheet",
"Post-Questionnaire", "Writing_Task_Evaluation")
i=4
path = "./raw_data/"
RAs = substr(list.files(path = path, pattern=dataSheets[i]), nchar(dataSheets[i])+2, nchar(dataSheets[i])+3)
RAs
#install.packages("xlsx")
library(xlsx)
dataSheets = c("Debrief", "Distraction_Assignment", "Note_sheet",
"Post-Questionnaire", "Writing_Task_Evaluation")
outList = vector("list", length=length(dataSheets))
names(outList) = dataSheets
dat = data.frame(NULL)
for (i in 1:length(dataSheets)) {
path = "./raw_data/"
RAs = substr(list.files(path = path, pattern=dataSheets[i]), nchar(dataSheets[i])+2, nchar(dataSheets[i])+3)
for (j in 1:length(RAs)) {
fileName = paste(path, dataSheets[i], "_", RAs[j], ".xlsx", sep="")
temp = read.xlsx(fileName, 1, stringsAsFactors=F)
temp$Entrant = RAs[j]
print(fileName); print(names(temp))
dat = rbind(dat, temp)
# Save to an object with variable name
# I'm going to use eval(parse()) and you don't get to pretend you're better than me
}
outList[[i]] = dat
dat = data.frame(NULL)
}
# fix subno name
names(outList[[2]])[1] = "Subject"
# checking for duplicates (e.g. two different subs entered w/ same ID)
# Note that it is right that "digits" has frequent duplicates!
for (i in 1:length(dataSheets)) {
print(names(outList)[i])
print(subset(table(outList[[i]]$Subject), table(outList[[i]]$Subject)>1))
}
debrief = outList[[1]]
debrief[debrief$Subject == 168,] # bad
debrief = debrief[!(debrief$Subject %in% c("165 or 166?", "168")),]
# Gonna put thse back into list b/c I think that makes reshaping easier
outList[[1]] = debrief ###
distract = outList[[2]]
distract = distract[!(distract$Subject %in% c(168, 170, 203, 33)),] # ??? doesn't remove rows?
distract = distract[!(distract$Subject == "165 or 167?"),]
distract = distract[complete.cases(distract),]
#
outList[[2]] = distract ###
notes = outList[[3]]
notes[notes$Subject == 150,]
notes = notes[-265,] # deleting duplicate row
#
outList[[3]] = notes ###
postQ = outList[[4]]
eval = outList[[5]]
eval = eval[!(eval$Subject %in% c(140, 63, 82)),]
#
outList[[5]] = eval ###
# Bring in digits data, previously cleaned in 2d4d.R
digits = read.delim("./cleaned_data/2d4d.txt")
names(digits)[1] = "Subject"
outList[[6]] = digits
# Aggregate everything into a single huge spreadsheet
require(reshape2)
molten = melt(outList, id.var = "Subject")
outDat = dcast(molten, Subject ~ ...)
# If it's aggregating, you've done it wrong!
outDat$Violence = ifelse(outDat$Condition_Note_sheet == 1 |
outDat$Condition_Note_sheet == 2, "Violent", "Nonviolent")
outDat$Difficulty = ifelse(outDat$Condition_Note_sheet == 2 |
outDat$Condition_Note_sheet == 4, "Hard", "Easy")
table(outDat$Condition_Note_sheet, outDat$Violence, outDat$Difficulty, useNA='always')
# may tidy up column order here, make more columns, prettier names, etc.
write.table(outDat, "./cleaned_data/aggregated_data.txt", sep="\t", row.names=F)
dat = read.delim("./cleaned_data/aggregated_data.txt", sep="\t", stringsAsFactors=F)
# TO DO: Check & discard subjects according to gameplay vars
# how do i aggregate all this data from this disparate spreadsheets?
# closest I can think of is my loop below which retrieves for a filename
# Subject 80 "bad"?
#install.packages("xlsx")
library(xlsx)
dataSheets = c("Debrief", "Distraction_Assignment", "Note_sheet",
"Post-Questionnaire", "Writing_Task_Evaluation")
outList = vector("list", length=length(dataSheets))
names(outList) = dataSheets
dat = data.frame(NULL)
for (i in 1:length(dataSheets)) {
path = "./raw_data/"
RAs = substr(list.files(path = path, pattern=dataSheets[i]), nchar(dataSheets[i])+2, nchar(dataSheets[i])+3)
for (j in 1:length(RAs)) {
fileName = paste(path, dataSheets[i], "_", RAs[j], ".xlsx", sep="")
temp = read.xlsx(fileName, 1, stringsAsFactors=F)
temp$Entrant = RAs[j]
print(fileName); print(names(temp))
dat = rbind(dat, temp)
# Save to an object with variable name
# I'm going to use eval(parse()) and you don't get to pretend you're better than me
}
outList[[i]] = dat
dat = data.frame(NULL)
}
# fix subno name
names(outList[[2]])[1] = "Subject"
# checking for duplicates (e.g. two different subs entered w/ same ID)
# Note that it is right that "digits" has frequent duplicates!
for (i in 1:length(dataSheets)) {
print(names(outList)[i])
print(subset(table(outList[[i]]$Subject), table(outList[[i]]$Subject)>1))
}
debrief = outList[[1]]
debrief[debrief$Subject == 168,] # bad
debrief = debrief[!(debrief$Subject %in% c("165 or 166?", "168")),]
# Gonna put thse back into list b/c I think that makes reshaping easier
outList[[1]] = debrief ###
distract = outList[[2]]
distract = distract[!(distract$Subject %in% c(168, 170, 203, 33)),] # ??? doesn't remove rows?
distract = distract[!(distract$Subject == "165 or 167?"),]
distract = distract[complete.cases(distract),]
#
outList[[2]] = distract ###
notes = outList[[3]]
notes[notes$Subject == 150,]
notes = notes[-265,] # deleting duplicate row
#
outList[[3]] = notes ###
postQ = outList[[4]]
eval = outList[[5]]
eval = eval[!(eval$Subject %in% c(140, 63, 82)),]
#
outList[[5]] = eval ###
# Bring in digits data, previously cleaned in 2d4d.R
digits = read.delim("./cleaned_data/2d4d.txt")
names(digits)[1] = "Subject"
outList[[6]] = digits
# Aggregate everything into a single huge spreadsheet
require(reshape2)
molten = melt(outList, id.var = "Subject")
outDat = dcast(molten, Subject ~ ...)
# If it's aggregating, you've done it wrong!
outDat$Violence = ifelse(outDat$Condition_Note_sheet == 1 |
outDat$Condition_Note_sheet == 2, "Violent", "Nonviolent")
outDat$Difficulty = ifelse(outDat$Condition_Note_sheet == 2 |
outDat$Condition_Note_sheet == 4, "Hard", "Easy")
table(outDat$Condition_Note_sheet, outDat$Violence, outDat$Difficulty, useNA='always')
# may tidy up column order here, make more columns, prettier names, etc.
write.table(outDat, "./cleaned_data/aggregated_data.txt", sep="\t", row.names=F)
dat = read.delim("./cleaned_data/aggregated_data.txt", sep="\t", stringsAsFactors=F)
dim(outDat)
dim(dat)
outDat[245,1:10]
dat[245,1:10]
z = read.delim("./cleaned_data/aggregated_data.txt", sep="\t", stringsAsFactors=F)
write(z, "temp_debug.txt", sep="\t", row.names=F)
write.table(z, "temp_debug.txt", sep="\t", row.names=F)
dim(z)
View(z)
outDat[,1] == z[,1]
View(outDat)
# TO DO: Check & discard subjects according to gameplay vars
# how do i aggregate all this data from this disparate spreadsheets?
# closest I can think of is my loop below which retrieves for a filename
# Subject 80 "bad"?
#install.packages("xlsx")
library(xlsx)
dataSheets = c("Debrief", "Distraction_Assignment", "Note_sheet",
"Post-Questionnaire", "Writing_Task_Evaluation")
outList = vector("list", length=length(dataSheets))
names(outList) = dataSheets
dat = data.frame(NULL)
for (i in 1:length(dataSheets)) {
path = "./raw_data/"
RAs = substr(list.files(path = path, pattern=dataSheets[i]), nchar(dataSheets[i])+2, nchar(dataSheets[i])+3)
for (j in 1:length(RAs)) {
fileName = paste(path, dataSheets[i], "_", RAs[j], ".xlsx", sep="")
temp = read.xlsx(fileName, 1, stringsAsFactors=F)
temp$Entrant = RAs[j]
print(fileName); print(names(temp))
dat = rbind(dat, temp)
# Save to an object with variable name
# I'm going to use eval(parse()) and you don't get to pretend you're better than me
}
outList[[i]] = dat
dat = data.frame(NULL)
}
# fix subno name
names(outList[[2]])[1] = "Subject"
# checking for duplicates (e.g. two different subs entered w/ same ID)
# Note that it is right that "digits" has frequent duplicates!
for (i in 1:length(dataSheets)) {
print(names(outList)[i])
print(subset(table(outList[[i]]$Subject), table(outList[[i]]$Subject)>1))
}
debrief = outList[[1]]
debrief[debrief$Subject == 168,] # bad
debrief = debrief[!(debrief$Subject %in% c("165 or 166?", "168")),]
# Gonna put thse back into list b/c I think that makes reshaping easier
outList[[1]] = debrief ###
distract = outList[[2]]
distract = distract[!(distract$Subject %in% c(168, 170, 203, 33)),] # ??? doesn't remove rows?
distract = distract[!(distract$Subject == "165 or 167?"),]
distract = distract[complete.cases(distract),]
#
outList[[2]] = distract ###
notes = outList[[3]]
notes[notes$Subject == 150,]
notes = notes[-265,] # deleting duplicate row
#
outList[[3]] = notes ###
postQ = outList[[4]]
eval = outList[[5]]
eval = eval[!(eval$Subject %in% c(140, 63, 82)),]
#
outList[[5]] = eval ###
# Bring in digits data, previously cleaned in 2d4d.R
digits = read.delim("./cleaned_data/2d4d.txt")
names(digits)[1] = "Subject"
outList[[6]] = digits
# Aggregate everything into a single huge spreadsheet
require(reshape2)
molten = melt(outList, id.var = "Subject")
outDat = dcast(molten, Subject ~ ...)
# If it's aggregating, you've done it wrong!
outDat$Violence = ifelse(outDat$Condition_Note_sheet == 1 |
outDat$Condition_Note_sheet == 2, "Violent", "Nonviolent")
outDat$Difficulty = ifelse(outDat$Condition_Note_sheet == 2 |
outDat$Condition_Note_sheet == 4, "Hard", "Easy")
table(outDat$Condition_Note_sheet, outDat$Violence, outDat$Difficulty, useNA='always')
# may tidy up column order here, make more columns, prettier names, etc.
write.table(outDat, "./cleaned_data/aggregated_data.txt", sep="\t", row.names=F)
# TO DO: Check & discard subjects according to gameplay vars
# how do i aggregate all this data from this disparate spreadsheets?
# closest I can think of is my loop below which retrieves for a filename
# Subject 80 "bad"?
#install.packages("xlsx")
library(xlsx)
dataSheets = c("Debrief", "Distraction_Assignment", "Note_sheet",
"Post-Questionnaire", "Writing_Task_Evaluation")
outList = vector("list", length=length(dataSheets))
names(outList) = dataSheets
dat = data.frame(NULL)
for (i in 1:length(dataSheets)) {
path = "./raw_data/"
RAs = substr(list.files(path = path, pattern=dataSheets[i]), nchar(dataSheets[i])+2, nchar(dataSheets[i])+3)
for (j in 1:length(RAs)) {
fileName = paste(path, dataSheets[i], "_", RAs[j], ".xlsx", sep="")
temp = read.xlsx(fileName, 1, stringsAsFactors=F)
temp$Entrant = RAs[j]
print(fileName); print(names(temp))
dat = rbind(dat, temp)
# Save to an object with variable name
# I'm going to use eval(parse()) and you don't get to pretend you're better than me
}
outList[[i]] = dat
dat = data.frame(NULL)
}
# fix subno name
names(outList[[2]])[1] = "Subject"
# checking for duplicates (e.g. two different subs entered w/ same ID)
# Note that it is right that "digits" has frequent duplicates!
for (i in 1:length(dataSheets)) {
print(names(outList)[i])
print(subset(table(outList[[i]]$Subject), table(outList[[i]]$Subject)>1))
}
debrief = outList[[1]]
debrief[debrief$Subject == 168,] # bad
debrief = debrief[!(debrief$Subject %in% c("165 or 166?", "168")),]
# Gonna put thse back into list b/c I think that makes reshaping easier
outList[[1]] = debrief ###
distract = outList[[2]]
distract = distract[!(distract$Subject %in% c(168, 170, 203, 33)),] # ??? doesn't remove rows?
distract = distract[!(distract$Subject == "165 or 167?"),]
distract = distract[complete.cases(distract),]
#
outList[[2]] = distract ###
notes = outList[[3]]
notes[notes$Subject == 150,]
notes = notes[-265,] # deleting duplicate row
#
outList[[3]] = notes ###
postQ = outList[[4]]
eval = outList[[5]]
eval = eval[!(eval$Subject %in% c(140, 63, 82)),]
#
outList[[5]] = eval ###
# Bring in digits data, previously cleaned in 2d4d.R
digits = read.delim("./cleaned_data/2d4d.txt")
names(digits)[1] = "Subject"
outList[[6]] = digits
# Aggregate everything into a single huge spreadsheet
require(reshape2)
molten = melt(outList, id.var = "Subject")
outDat = dcast(molten, Subject ~ ...)
# If it's aggregating, you've done it wrong!
outDat$Violence = ifelse(outDat$Condition_Note_sheet == 1 |
outDat$Condition_Note_sheet == 2, "Violent", "Nonviolent")
outDat$Difficulty = ifelse(outDat$Condition_Note_sheet == 2 |
outDat$Condition_Note_sheet == 4, "Hard", "Easy")
table(outDat$Condition_Note_sheet, outDat$Violence, outDat$Difficulty, useNA='always')
# may tidy up column order here, make more columns, prettier names, etc.
write.table(outDat, "./cleaned_data/aggregated_data.txt", sep="\t", row.names=F)
dim(outDat)
z = read.delim("./cleaned_data/aggregated_data.txt", sep="\t", stringsAsFactors=F)
View(z)
z = read.delim("./cleaned_data/aggregated_data.txt", sep="\t", stringsAsFactors=F)
dim(outDat)
write.table(outDat, "./cleaned_data/aggregated_data.txt", sep="\t", row.names=F)
aggregated_data <- read.delim("~/GitHub/vg-dissertation/raw-data-prep/cleaned_data/aggregated_data.txt")
View(aggregated_data)
digits[digits$Subject == 69]
digits[digits$Subject == 69,]
# TO DO: Check & discard subjects according to gameplay vars
# how do i aggregate all this data from this disparate spreadsheets?
# closest I can think of is my loop below which retrieves for a filename
# Subject 80 "bad"?
#install.packages("xlsx")
library(xlsx)
dataSheets = c("Debrief", "Distraction_Assignment", "Note_sheet",
"Post-Questionnaire", "Writing_Task_Evaluation")
outList = vector("list", length=length(dataSheets))
names(outList) = dataSheets
dat = data.frame(NULL)
for (i in 1:length(dataSheets)) {
path = "./raw_data/"
RAs = substr(list.files(path = path, pattern=dataSheets[i]), nchar(dataSheets[i])+2, nchar(dataSheets[i])+3)
for (j in 1:length(RAs)) {
fileName = paste(path, dataSheets[i], "_", RAs[j], ".xlsx", sep="")
temp = read.xlsx(fileName, 1, stringsAsFactors=F)
temp$Entrant = RAs[j]
print(fileName); print(names(temp))
dat = rbind(dat, temp)
# Save to an object with variable name
# I'm going to use eval(parse()) and you don't get to pretend you're better than me
}
outList[[i]] = dat
dat = data.frame(NULL)
}
# fix subno name
names(outList[[2]])[1] = "Subject"
# checking for duplicates (e.g. two different subs entered w/ same ID)
# Note that it is right that "digits" has frequent duplicates!
for (i in 1:length(dataSheets)) {
print(names(outList)[i])
print(subset(table(outList[[i]]$Subject), table(outList[[i]]$Subject)>1))
}
debrief = outList[[1]]
debrief[debrief$Subject == 168,] # bad
debrief = debrief[!(debrief$Subject %in% c("165 or 166?", "168")),]
# Gonna put thse back into list b/c I think that makes reshaping easier
outList[[1]] = debrief ###
distract = outList[[2]]
distract = distract[!(distract$Subject %in% c(168, 170, 203, 33)),] # ??? doesn't remove rows?
distract = distract[!(distract$Subject == "165 or 167?"),]
distract = distract[complete.cases(distract),]
#
outList[[2]] = distract ###
notes = outList[[3]]
notes[notes$Subject == 150,]
notes = notes[-265,] # deleting duplicate row
#
outList[[3]] = notes ###
postQ = outList[[4]]
eval = outList[[5]]
eval = eval[!(eval$Subject %in% c(140, 63, 82)),]
#
outList[[5]] = eval ###
# Bring in digits data, previously cleaned in 2d4d.R
digits = read.delim("./cleaned_data/2d4d.txt")
names(digits)[1] = "Subject"
outList[[6]] = digits
# Aggregate everything into a single huge spreadsheet
require(reshape2)
molten = melt(outList, id.var = "Subject")
outDat = dcast(molten, Subject ~ ...)
# If it's aggregating, you've done it wrong!
outDat$Violence = ifelse(outDat$Condition_Note_sheet == 1 |
outDat$Condition_Note_sheet == 2, "Violent", "Nonviolent")
outDat$Difficulty = ifelse(outDat$Condition_Note_sheet == 2 |
outDat$Condition_Note_sheet == 4, "Hard", "Easy")
table(outDat$Condition_Note_sheet, outDat$Violence, outDat$Difficulty, useNA='always')
# may tidy up column order here, make more columns, prettier names, etc.
write.table(outDat, "./cleaned_data/aggregated_data.txt", sep="\t", row.names=F)
z = read.delim("./cleaned_data/aggregated_data.txt", sep="\t", stringsAsFactors=F)
z = read.delim("./cleaned_data/aggregated_data.txt",
quote="", sep="\t",
stringsAsFactors=F)
dim(outData)
dim(outDat)
dim(z)
names(dat)
dat = read.delim("./cleaned_data/aggregated_data.txt",
quote="", sep="\t",
stringsAsFactors=F)
names(dat)
names(outDat)[1]
names(dat)[1]
noteCols = grep("note", names(outDat), value=T)
noteCols
noteCols = grep("Note", names(outDat), value=T)
noteCols
names(outDat)
head(outDat$Why._Debrief)
noteCols = c("julNotes_", "racNotes_", "tayNotes_","Notes_Note_sheet","Why._Debrief")
noteCols = c("julNotes_", "racNotes_", "tayNotes_","Notes_Note_sheet","Why._Debrief")
noteCols = c("julNotes_", "racNotes_", "tayNotes_","Notes_Note_sheet","Why._Debrief")
dim(outDat)
outDat = outDat[,!(names(outDat) %in% noteCols)]
dim(outDat)
write.table(outDat, "./cleaned_data/aggregated_data.txt", sep="\t", row.names=F)
dat = read.delim("./cleaned_data/aggregated_data.txt",
#quote="",
sep="\t",
stringsAsFactors=F)
dim(dat)
names(dat)
unique(dat$Good.Session_Note_sheet)
